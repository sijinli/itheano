# In this layer, I will init the weights from convet
# ----------------------------------------------
# Modified from t0014
#-----------------------------------------------------
# In this network, we explore whether we can learn from  
# the pose directly, rather than on pose features
# 
#
#
[l_img_feature]
type=data
inputs=s_img_feature
input_dims=1024

[l_target]
type=data
inputs=s_target
input_dims=51
neuron=linear[0.000833333333334,0]
# divided by 1200

[l_candidate]
type=data
inputs=s_candidate
input_dims=51
neuron=linear[0.000833333333334,0]
# divided by 1200

[l_gt_margin]
type=data
inputs=s_gt_margin
input_dims=1

[l_candidate_margin]
type=data
inputs=s_candidate_margin
input_dims=1



[net1_fc0]
type=fc
inputs=l_target
output_dims=1024
wd=0.00001
initW=0.1
initb=0
neuron=relu2
initWfunc=initfunc.get_w_fconv2(/opt/visal/tmp/for_sijin/Data/saved/c8k13/ConvNet__2014-12-02_17.33.30,fc_encode_0)
initBfunc=initfunc.get_b_fconv2(/opt/visal/tmp/for_sijin/Data/saved/c8k13/ConvNet__2014-12-02_17.33.30,fc_encode_0)


[net1_fc1]
type=fc
inputs=l_img_feature,net1_fc0
output_dims=1024
wd=0.00001,0.00001
initW=0.1,0.1
initb=0
neuron=relu2

[net1_fc2]
type=fc
inputs=net1_fc1
output_dims=1024
wd=0.00001
initW=0.01
initb=1
neuron=relu2


[net1_fc2_dropout]
type=dropout
inputs=net1_fc2
keep=0.5


[net1_fc3]
type=fc
inputs=net1_fc2_dropout
output_dims=1
wd=0.00001
initW=0.01
initb=1

[net2_fc0]
type=fc
inputs=l_candidate
output_dims=1024
wd=0.00001
initW=0.1
initb=0
neuron=relu2
weightSource=net1_fc0
biasSource=net1_fc0

[net2_fc1]
type=fc
inputs=l_img_feature,net2_fc0
output_dims=1024
wd=0.00001,0.00001
initW=0.1,0.1
initb=0
weightSource=net1_fc1[0],net1_fc1[1]
biasSource=net1_fc1
neuron=relu2

[net2_fc2]
type=fc
inputs=net2_fc1
output_dims=1024
wd=0.00001
initW=0.01
initb=1
neuron=relu2
weightSource=net1_fc2
biasSource=net1_fc2


[net2_fc2_dropout]
type=dropout
inputs=net2_fc2
keep=0.5


[net2_fc3]
type=fc
inputs=net2_fc2_dropout
output_dims=1
wd=0.00001
initW=0.01
initb=1
weightSource=net1_fc3
biasSource=net1_fc3


[net1_score]
type=eltsum
inputs=net1_fc3, l_gt_margin
coeffs=1,1

[net2_score]
type=eltsum
inputs=net2_fc3, l_candidate_margin
coeffs=1,1

[net2_mmcost]
type=cost.maxmargin
inputs=net1_score,net2_score
neuron=relu2

[network1]
type=network
cost_layer_names=
data_layer_names=l_img_feature, l_target, l_gt_margin
output_layer_names=net1_score
layer_with_weights=net1_fc0,net1_fc1,net1_fc2, net1_fc3

[network2]
type=network
cost_layer_names=net2_mmcost
data_layer_names=l_img_feature, l_target, l_candidate, l_gt_margin,l_candidate_margin
output_layer_names=net1_fc2, net2_fc1
layer_with_weights=net1_fc0,net1_fc1, net1_fc2, net1_fc3

