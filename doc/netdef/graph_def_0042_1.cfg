# Just change coeff = 5
# Same as 0042
#-----------------------------------------
# Modified from 0041
# In this version, I will try to use very smaller number of nodes in the last layer
# So that try to reduce the overfitting problem
#---------------------------------------------
# Modified from 0037
# all the wd is set to 0.01
# Then the network will be trained so that the regularization term will not be 
# divided by n
# ---------------------------------------------
# Modified from 0034_corrected_version
# Here I 
# ---------------------------------------------
# It is strange the performance of current saved 0034 version is 
# worse than its "parent"" network
# I will save a check network and check its performance
# So all the learning rates here is zero
# Modified from 0023
#---------------------------------------------------
# Modified from 0022
# This version  I remove sqdiff cost from the network
# 
# Modified from 0021
# This version will init the weights 
#------------------------------------
# Combination  of 0012 and 0020
# 2015_02_02_acm_act_14_exp_2_19_graph_0012/
# FCJ0_act_14_graph_0020_test
#-------------------------------------


[imgdata]
type=data
inputs=s_imgdata
input_dims=(3, 112,112)
#channel, height, width

[joints]
type=data
inputs=s_joints
input_dims=51

[candidate_joints]
type=data
inputs=s_candidate_joints
input_dims=51


[l_gt_margin]
type=data
inputs=s_gt_margin
input_dims=1

[l_candidate_margin]
type=data
inputs=s_candidate_margin
input_dims=1



[conv1]
type=conv
inputs=imgdata
sizeX=9
sizeY=9
filters=32
strideX=1
strideY=1
board_mode=valid
initW=0.00005
initb=0
wd=0
neuron=relu2
epsW=0.0005
epsB=0.002
initWfunc=initfunc.gwfp(/opt/visal/tmp/for_sijin/Data/saved/theano_models/2015_02_02_acm_act_14_exp_2_19_graph_0012/)
initBfunc=initfunc.gbfp(/opt/visal/tmp/for_sijin/Data/saved/theano_models/2015_02_02_acm_act_14_exp_2_19_graph_0012/)
# 32 @ 104 x 104

[pool1]
type=pool
inputs=conv1
sizeX=3
sizeY=3
strideX=2
strideY=2
pooling_type=max
# 32 @ 52 x 52

[conv2]
type=conv
inputs=pool1
sizeX=5
sizeY=5
filters=64
strideX=1
strideY=1
board_mode=valid
initW=0.001
initb=0
wd=0
neuron=relu2
epsW=0.0005
epsB=0.002
initWfunc=initfunc.gwfp(/opt/visal/tmp/for_sijin/Data/saved/theano_models/2015_02_02_acm_act_14_exp_2_19_graph_0012/)
initBfunc=initfunc.gbfp(/opt/visal/tmp/for_sijin/Data/saved/theano_models/2015_02_02_acm_act_14_exp_2_19_graph_0012/)
# 64 @ 48 x 48

[pool2]
type=pool
inputs=conv2
sizeX=3
sizeY=3
strideX=2
strideY=2
pooling_type=max
# 64 @ 24 x 24


[conv3]
type=conv
inputs=pool2
sizeX=5
sizeY=5
filters=64
strideX=1
strideY=1
board_mode=valid
initW=0.001
initb=0
wd=0
epsW=0.0005
epsB=0.002
initWfunc=initfunc.gwfp(/opt/visal/tmp/for_sijin/Data/saved/theano_models/2015_02_02_acm_act_14_exp_2_19_graph_0012/)
initBfunc=initfunc.gbfp(/opt/visal/tmp/for_sijin/Data/saved/theano_models/2015_02_02_acm_act_14_exp_2_19_graph_0012/)
#neuron=relu
# 64 @ 20 x 20

[pool3]
type=pool
inputs=conv3
sizeX=3
sizeY=3
strideX=2
strideY=2
pooling_type=max
# 64 @ 10 x 10


[fc_j0]
type=fc
inputs=pool3
output_dims=1024
wd=0.001
initW=0.001
epsW=0.0005
epsB=0.002
initb=0
neuron=relu2
initWfunc=initfunc.gwfp(/opt/visal/tmp/for_sijin/Data/saved/theano_models/2015_02_02_acm_act_14_exp_2_19_graph_0012/)
initBfunc=initfunc.gbfp(/opt/visal/tmp/for_sijin/Data/saved/theano_models/2015_02_02_acm_act_14_exp_2_19_graph_0012/)

[fc_j0_scale]
type=neuron
inputs=fc_j0
neuron=linear[0.1,0]


[img_feature]
type=fc
inputs=fc_j0_scale
output_dims=1024
wd=0.001
initW=0.01
initb=0
neuron=relu2
initWfunc=initfunc.gwfp(/opt/visal/tmp/for_sijin/Data/saved/theano_models/2015_02_28_FCJ0_act_14_cosine_test_1/,fc_f0)
initBfunc=initfunc.gbfp(/opt/visal/tmp/for_sijin/Data/saved/theano_models/2015_02_28_FCJ0_act_14_cosine_test_1/,fc_f0)
epsW=0.0005
epsB=0.002
#  = fc0_img in 0020

[net1_fc_0]
type=fc
inputs=joints
output_dims=1024
wd=0.001
initW=0.1
initb=0
neuron=relu2
initWfunc=initfunc.gwfp(/opt/visal/tmp/for_sijin/Data/saved/theano_models/2015_02_28_FCJ0_act_14_cosine_test_1/,fc_encode0)
initBfunc=initfunc.gbfp(/opt/visal/tmp/for_sijin/Data/saved/theano_models/2015_02_28_FCJ0_act_14_cosine_test_1/,fc_encode0)
epsW=0.0005
epsB=0.002
# = net1_fc0_jt

[net1_fc_1]
type=fc
inputs=img_feature,net1_fc_0
output_dims=512
wd=0.001,0.001
initW=0.01,0.01
initb=0
neuron=relu2
epsW=0.0005,0.0005
epsB=0.002
# = net1_fc1

[net1_fc_2]
type=fc
inputs=net1_fc_1
output_dims=256
wd=0.001
initW=0.1
initb=0
neuron=relu2
epsW=0.0005
epsB=0.002
# = net1_fc2

[net1_fc_2_dropout]
type=dropout
inputs=net1_fc_2
keep=0.25

[net1_fc_3]
type=fc
inputs=net1_fc_2_dropout
output_dims=1
wd=0.001
initW=0.1
initb=1
epsW=0.0005
epsB=0.002

#= net1_fc3
###################
[net2_fc_0]
type=fc
inputs=candidate_joints
output_dims=1024
wd=0.001
initW=0.1
initb=0
neuron=relu2
weightSource=net1_fc_0
biasSource=net1_fc_0



[net2_fc_1]
type=fc
inputs=img_feature,net2_fc_0
output_dims=512
wd=0.001,0.001
initW=0.1,0.1
initb=0
neuron=relu2
weightSource=net1_fc_1[0],net1_fc_1[1]
biasSource=net1_fc_1



[net2_fc_2]
type=fc
inputs=net2_fc_1
output_dims=256
wd=0.001
initW=0.01
initb=0
weightSource=net1_fc_2
biasSource=net1_fc_2
neuron=relu2

[net2_fc_2_dropout]
type=dropout
inputs=net2_fc_2
keep=0.25


[net2_fc_3]
type=fc
inputs=net2_fc_2_dropout
output_dims=1
wd=0.001
initW=0.01
initb=1
weightSource=net1_fc_3
biasSource=net1_fc_3


[net1_score]
type=eltsum
inputs=net1_fc_3, l_gt_margin
coeffs=1,1

[net2_score]
type=eltsum
inputs=net2_fc_3, l_candidate_margin
coeffs=1,1

[net2_mmcost]
type=cost.maxmargin
inputs=net1_score,net2_score
neuron=relu2
coeff=0.5

[feature_net]
type=network
cost_layer_names=
data_layer_names=imgdata
output_layer_names=fc_j0_scale
layer_with_weights=

[score_net]
type=network
cost_layer_names=
data_layer_names=img_feature,joints,l_gt_margin
output_layer_names=net1_score
layer_with_weights=


[train_net]
type=network
data_layer_names=imgdata,joints,candidate_joints,l_gt_margin,l_candidate_margin
cost_layer_names=net2_mmcost
output_layer_names=net1_score,net2_score
layer_with_weights=img_feature,net1_fc_0,net1_fc_1,net1_fc_2,net1_fc_3

