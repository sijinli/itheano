
Note{
DATE: Jan 16, 2015
Network 2: The only difference between network 2 and network 1 is that I use different relu in the maxmargin layer. 
In the network 2's version, it is switch(X>0, X, 0). 
Therefore, it will have gradients only when the cost is greater than zero.
The results varies a lot
[ Here is the weights vs gradients 
net1_fc1_weights_0:	 v:+4.494107e-01 	 g: +1.700636e-02 	 [+3.784147e-02]
net1_fc1_weights_1:	 v:+7.989296e-01 	 g: +6.362572e-02 	 [+7.963870e-02]
net1_fc1_biaes_0:	 v:+1.309456e+01 	 g: +6.498061e-01 	 [+4.962413e-02]
net1_fc2_weights_0:	 v:+1.429397e+01 	 g: +3.704958e+00 	 [+2.591973e-01]
net1_fc2_biaes_0:	 v:+0.000000e+00 	 g: +0.000000e+00 	 [+nan]
]
file_saved:/public/sijinli2/ibuffer/2015-01-16/itheano_test_act14_net2_test1_2014_01_16

I find the problem. 
Because I didn't preprocess the data, so that the margin will be extremely large.
Also, it is not suitable for current network, 
}

RUN {
net1:saved to /public/sijinli2/ibuffer/2015-01-16/net1
}

RUN {
savepath:/public/sijinli2/ibuffer/2015-01-16/net2_test_for_stat_no_hold
exp_name=SP_t004_act_14
DP=mem
macid=15
JT=0002
EP=200
BSIZE=1024
run_mac=c8k$(macid)
TrainRange=0-132743
TestRange=132744-162007
K-candidate=200 
K-most-violated=0
net2:
}

RUN {DATE: Jan 21 2015
exp_name=SP_t004_act_14
DP=mem
macid=16
JT=0004
EP=200
BSIZE=1024
run_mac=c8k$(macid)
TrainRange=0-132743
TestRange=132744-162007

net4:/public/sijinli2/ibuffer/2015-01-16/net4_test_for_stat

COMMENT: This time, I use larger candidate set. So that it can search a larger space. 
}

RUN {
DATE: Feb 1 2015
/opt/visal/tmp/for_sijin/tmp/tmp_theano  <-- A mistake | I add dropout on scores | so stupid

/opt/visal/tmp/for_sijin/Data/saved/theano_models/acm_act_14_exp_2_01_31_2015_16/
}

RUN {
/opt/visal/tmp/for_sijin/Data/saved/theano_models/2015_02_01_acm_act_14_exp_2_15
The performance becomes to decrease at some points because nan appears.

DATE: Feb 1, 2015
exp_name=SP_t004_act_14
DP=mem
macid=17
JT=0010
EP=200
BSIZE=1024
run_mac=c8k$(macid)
KC=200
KMV=100
MAXNUM=100
TrainRange=0-132743
TestRange=132744-162007
save_name=$(exp_name)_$(JT)
save_folder = /opt/visal/tmp/for_sijin/Data/saved/theano_models/
/opt/visal/tmp/for_sijin/Data/saved/theano_models/SP_t004_act_14_0010
COMMENT: Dropout +  one more layer
MPJPE: 86.3369

}

RUN {
Feb 2 2015
/opt/visal/tmp/for_sijin/Data/saved/theano_models/2015_02_02_acm_act_14_exp_2_19_graph_0012/
Eval@Feb4-2015-09:40AM: mean mpjpe = 79.672750975 epoch = 71
Eval@Feb5-2015-09:44AM: mean mpjpe = 79.679860815 epoch = 120
Eval@Feb11-2015-09:44AM: mean mpjpe =78.1785291767 epoch = 138


Feb 3 2015
/opt/visal/tmp/for_sijin/Data/saved/theano_models/SP_t004_act_14_graph_0013/
With smaller keep and number nodes, it still tends to overfit.
MPJPE=87.11156 ( However, it is worse than previous performance) Random 20000
MPJPE=80.8717975359 (ALL, epoch 70)
MPJPE=79.692556 (KC=20000, epoch 79)
}

RUN {
Feb 3 2015
exp_name=Embedding_ASM_act_14_exp_2_ACCV_fc_j0
}



NOTE {
exp_name=ASM_act_12_exp_4
DP=croppedjt
JT=0012
EP=200
BSIZE=128
/opt/visal/tmp/for_sijin/Data/saved/theano_models/2015_02_04_ASM_act_12_exp_4_18_graph_0012
mean mpjpe = 176.306504863
}

RUN {
exp_name=FCJ0_act_12
DP=mem
macid=15
JT=0016
EP=200
BSIZE=128
run_mac=c8k${macid}
TrainRange=0-76047
TestRange=76048-105367
test_freq=15
save_name=2015_02_08_FCJ0_act_12_graph_0016
COMMENTS: The scale of the input is really important
COMMENTS: MPJPE@200 epach:170.924891536
}

RUN {
Feb 8
exp_name=ASM_act_3_exp_8
DP=croppedjt
macid=14
JT=0012
EP=200
BSIZE=128
run_mac=c8k$(macid)
TrainRange=0-158787
TestRange=158788-223031
/opt/visal/tmp/for_sijin/Data/saved/theano_models/2015_02_08_ASM_act_3_exp_8_14_graph_0012
COMMENTS:14 is macid
mean mpjpe = 136.896386105

exp_name=ASM_act_4_exp_5
DP=croppedjt
macid=18
JT=0012
EP=200
BSIZE=128
run_mac=c8k$(macid)
TrainRange=0-109423
TestRange=109424-148731
/opt/visal/tmp/for_sijin/Data/saved/theano_models/2015_02_08_ASM_act_4_exp_5_18_graph_0012
mean mpjpe = 117.198643991
}

NOTE{
exp_name=FCJ0_act_14
DP=mem
macid=15
JT=0016
EP=200
BSIZE=128
run_mac=c8k${macid}
TrainRange=0-132743
TestRange=132744-162007
test_freq=15
save_name=2015_02_09_FCJ0_act_14_test
/opt/visal/tmp/for_sijin/Data/saved/theano_models/2015_02_09_FCJ0_act_14_test
mean mpjpe = 82.988910692
}

RUN {
Feb 14 2015
exp_name=ASM_act_15_exp_9
DP=croppedjt
macid=19
JT=0012
EP=200
BSIZE=128
run_mac=c8k$(macid)

TrainRange=0-79411
TestRange=79412-107715

test_freq=15
save_name=2015_02_14_$(exp_name)_$(macid)_graph_$(JT)
/opt/visal/tmp/for_sijin/Data/saved/theano_models/2015_02_14_ASM_act_15_exp_9_19_graph_0012
}

RUN {
exp_name=ASM_act_5_exp_10
DP=croppedjt
macid=17
JT=0012
EP=200
BSIZE=128
run_mac=c8k$(macid)

TrainRange=0-72435
TestRange=72436-103079
/opt/visal/tmp/for_sijin/Data/saved/theano_models/2015_02_14_ASM_act_5_exp_10_17_graph_0012
}

NOTE {
exp_name=FCJ0_act_14
DP=mem
macid=13
JT=0020
EP=200
BSIZE=1024
run_mac=c8k${macid}
KC=200
KMV=100
MAXNUM=100
TrainRange=0-132743
TestRange=132744-162007
/opt/visal/tmp/for_sijin/Data/saved/theano_models/FCJ0_act_14_graph_0020_test
}

NOTE {
exp_name=ASM_act_14_exp_2
DP=croppedjt
macid=13
JT=0022
EP=200
BSIZE=128
un_mac=c8k${macid}
KC=200
KMV=100
MAXNUM=10
TrainRange=0-132743
TestRange=132744-162007
save_name=DEBUG_TEST_0023
/opt/visal/tmp/for_sijin/Data/saved/theano_models/DEBUG_TEST_0022
mean mpjpe = 77.4093566823  <------ On pose prediction part

exp_name=ASM_act_14_exp_2
DP=croppedjt
macid=13
JT=0023
EP=200
BSIZE=128
run_mac=c8k${macid}
KC=200
KMV=100
MAXNUM=10
TrainRange=0-132743
TestRange=132744-162007
save_name=DEBUG_TEST_0023
/opt/visal/tmp/for_sijin/Data/saved/theano_models/DEBUG_TEST_0023
}

Record{
exp_name=FCJ0_act_14
DP=mem
macid=15
JT=0018
EP=200
BSIZE=128
run_mac=c8k${macid}
TrainRange=0-132743
TestRange=132744-162007
/opt/visal/tmp/for_sijin/Data/saved/theano_models/FCJ0_act_14_testbp
mean mpjpe = 80.5595836496
}

RUN {
exp_name=FCJ0_act_14
DP=mem
macid=15
JT=0024
EP=200
BSIZE=128
run_mac=c8k${macid}

TrainRange=0-132743
TestRange=132744-162007

test_freq=15
save_name=2015_02_17_FCJ0_act_14_again
/opt/visal/tmp/for_sijin/Data/saved/theano_models/2015_02_17_FCJ0_act_14_again/
mean mpjpe = 79.8749450703
}

RUN {
exp_name=ASM_act_14_exp_2
DP=croppedjt
macid=14
JT=0025
EP=200
BSIZE=128
run_mac=c8k$(macid)
KC=200
KMV=100
MAXNUM=10
TrainRange=0-132743
TestRange=132744-162007
DATE=2015_02_17
save_name=$(DATE)_$(exp_name)_graph_$(JT)
/opt/visal/tmp/for_sijin/Data/saved/theano_models/2015_02_17_ASM_act_14_exp_2_graph_0025
}

RUN {
exp_name=FCJ0_act_14
DP=mem
macid=15
JT=0027_1
EP=200
BSIZE=128
run_mac=c8k${macid}

TrainRange=0-132743
TestRange=132744-162007

test_freq=1
save_name=2015_02_28_FCJ0_act_14_cosine_test_1
SP_NOTE=
/opt/visal/tmp/for_sijin/Data/saved/theano_models/2015_02_28_FCJ0_act_14_cosine_test_1/
}

RUN {
exp_name=FCJ0_act_14
DP=mem
macid=13
JT=0028
EP=200
BSIZE=1024
run_mac=c8k${macid}
KC=200
KMV=1000
MAXNUM=100
TrainRange=0-132743
TestRange=132744-162007
save_name=${exp_name}_graph_${JT}_test_KMV_1000

I was trying two versions. 
##Now in processing
In the first version, I use KMV=100, on c8k16 
/opt/visal/tmp/for_sijin/Data/saved/theano_models/FCJ0_act_14_graph_0028_test_
[Random shuffled test, batch size 128, candidate 20000
Residuals for best match poses 51.6047676782,
mpjpe as mv_margin is 89.6173502302]
[Use train as test, random batch, size = 128, candidate 20000
Residuals for best match poses 16.9762548099
mpjpe as mv_margin is 24.2432484224
]

in the second version I use KMV=1000 on c8k15

}

RUN {
exp_name=FCJ0_act_14
DP=mem
macid=13
JT=0029
EP=200
BSIZE=1024
run_mac=c8k${macid}
KC=200
KMV=100
MAXNUM=100
TrainRange=0-132743
TestRange=132744-162007
save_name=${exp_name}_graph_${JT}_test_norm
EXTRA=--force-shuffle=1
/opt/visal/tmp/for_sijin/Data/saved/Test/FCJ0_act_14_graph_0029_test_norm/

[--epoch 29@72
Residuals for best match poses 16.8584867541
mpjpe as mv_margin is 34.1280347539
Residuals for best match poses 51.1792763669
mpjpe as mv_margin is 87.8447293153 ]
}

RUN {
exp_name=FCJ0_act_14
DP=mem
macid=13
JT=0030
EP=200
BSIZE=1024
run_mac=c8k${macid}
KC=200
KMV=100
MAXNUM=100
TrainRange=0-132743
TestRange=132744-162007
save_name=${exp_name}_graph_${JT}_test_norm
EXTRA=--force-shuffle=1
/opt/visal/tmp/for_sijin/Data/saved/Test/FCJ0_act_14_graph_0030_test_norm/
}



RUN {
exp_name=FCJ0_act_14
DP=mem
macid=13
JT=0029
EP=200
BSIZE=1024
run_mac=c8k${macid}
KC=200
KMV=100
MAXNUM=100
TrainRange=0-132743
TestRange=132744-162007
save_name=${exp_name}_graph_${JT}_test_norm
EXTRA=--force-shuffle=1 --cumulate-update

}
